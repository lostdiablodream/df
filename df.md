# OpenHands vs. Чат-интерфейс LLM: Расширенный анализ для разработки ПО

> **Версия отчёта:** февраль 2026  
> **Охват:** OpenHands v1 (SDK), SWE-Bench Verified / Pro, сравнение агентов, технологии LLM  
> **Аудитория:** Разработчики, тимлиды, DevOps-инженеры

---

## Содержание

1. [Исполнительное резюме](#1-исполнительное-резюме)
2. [Архитектура OpenHands](#2-архитектура-openhands)
3. [Масштабная сравнительная таблица: OpenHands vs. Чат](#3-масштабная-сравнительная-таблица)
4. [Сравнение агентных платформ](#4-сравнение-агентных-платформ)
5. [Топ-моделей для кодинга (2025–2026)](#5-топ-моделей-для-кодинга)
6. [Технологии внутри LLM-моделей](#6-технологии-внутри-llm-моделей)
7. [Технологии внутри агентных систем](#7-технологии-внутри-агентных-систем)
8. [Связь технологий моделей и агентов](#8-связь-технологий-моделей-и-агентов)
9. [Качество кодинга: детальный анализ](#9-качество-кодинга)
10. [Траблшутинг и отладка](#10-траблшутинг-и-отладка)
11. [Code Review](#11-code-review)
12. [Аналитика и исследовательские задачи](#12-аналитика-и-исследовательские-задачи)
13. [Бенчмарки и реальные метрики](#13-бенчмарки-и-реальные-метрики)
14. [Экономика и TCO](#14-экономика-и-tco)
15. [Рекомендации и сценарии применения](#15-рекомендации-и-сценарии-применения)

---

# Расшифровка аббревиатур

| Аббревиатура | Расшифровка | Контекст применения |
|---|---|---|
| **AI** | Artificial Intelligence — Искусственный интеллект | Общий термин для систем на основе ML/LLM |
| **API** | Application Programming Interface — Интерфейс программирования приложений | Способ подключения к LLM-моделям (Anthropic API, OpenAI API) |
| **AST** | Abstract Syntax Tree — Абстрактное синтаксическое дерево | Структура разбора кода для анализа и индексации |
| **BPE** | Byte-Pair Encoding — Байт-парное кодирование | Алгоритм токенизации текста/кода в LLM |
| **CI/CD** | Continuous Integration / Continuous Delivery — Непрерывная интеграция / доставка | Автоматизация сборки, тестирования, деплоя |
| **CLI** | Command Line Interface — Интерфейс командной строки | Способ запуска инструментов (Aider, Claude Code) |
| **CSS** | Cascading Style Sheets — Каскадные таблицы стилей | Язык стилизации веб-страниц |
| **DB** | Database — База данных | Хранилище структурированных данных |
| **DevOps** | Development + Operations — Разработка + эксплуатация | Культура и практики автоматизации IT-процессов |
| **DSL** | Domain-Specific Language — Предметно-ориентированный язык | BrowserGym DSL — язык команд для управления браузером |
| **GDPR** | General Data Protection Regulation — Общий регламент о защите данных | Европейский стандарт конфиденциальности данных |
| **GPU** | Graphics Processing Unit — Графический процессор | Аппаратное ускорение обучения и инференса LLM |
| **GUI** | Graphical User Interface — Графический пользовательский интерфейс | Визуальный интерфейс приложения |
| **HIPAA** | Health Insurance Portability and Accountability Act | Американский стандарт защиты медицинских данных |
| **HTML** | HyperText Markup Language — Язык гипертекстовой разметки | Язык структуры веб-страниц |
| **HTTP** | HyperText Transfer Protocol — Протокол передачи гипертекста | Протокол веб-запросов (используется при API-вызовах) |
| **IDE** | Integrated Development Environment — Интегрированная среда разработки | VS Code, Cursor, Windsurf |
| **IFT** | Instruction Following Fine-tuning — Дообучение следованию инструкциям | Этап обучения LLM на парах инструкция→ответ |
| **ITPM** | Input Tokens Per Minute — Входящих токенов в минуту | Метрика rate limit API Anthropic |
| **JS** | JavaScript | Язык программирования для веба и Node.js |
| **JSON** | JavaScript Object Notation — Объектная нотация JavaScript | Формат данных для API-запросов и конфигов |
| **KV Cache** | Key-Value Cache — Кэш ключей и значений | Механизм кэширования вычислений attention в LLM |
| **LLM** | Large Language Model — Большая языковая модель | Claude, GPT, Gemini, Qwen, DeepSeek и т.д. |
| **MCP** | Model Context Protocol — Протокол контекста модели | Стандарт Anthropic для подключения внешних инструментов к LLM |
| **MIT** | Massachusetts Institute of Technology | Лицензия с открытым исходным кодом (MIT License) |
| **ML** | Machine Learning — Машинное обучение | Раздел ИИ, основа LLM |
| **MoE** | Mixture of Experts — Смесь экспертов | Архитектура нейросети с условной активацией частей (Qwen, DeepSeek) |
| **MR** | Merge Request — Запрос на слияние | GitLab-аналог Pull Request |
| **npm** | Node Package Manager — Менеджер пакетов Node.js | Установка JS-зависимостей |
| **OTPM** | Output Tokens Per Minute — Исходящих токенов в минуту | Метрика rate limit API Anthropic |
| **PDF** | Portable Document Format — Переносимый формат документов | Формат файлов |
| **pip** | Pip Installs Packages — Менеджер пакетов Python | Установка Python-зависимостей |
| **PR** | Pull Request — Запрос на внесение изменений | GitHub-механизм предложения изменений в репозиторий |
| **RAG** | Retrieval-Augmented Generation — Генерация с извлечением | LLM + поиск по внешней базе знаний/кода |
| **ReAct** | Reasoning + Acting — Рассуждение + действие | Агентный паттерн: чередование размышления и исполнения |
| **REST** | Representational State Transfer | Архитектурный стиль API (HTTP-методы) |
| **RLHF** | Reinforcement Learning from Human Feedback — Обучение с подкреплением от человеческой обратной связи | Этап обучения LLM на оценках людей |
| **RLAIF** | Reinforcement Learning from AI Feedback | RLHF, где оценщиком выступает другая модель, а не человек |
| **RLM** | (Rate Limit) — Ограничение на частоту запросов | Технические ограничения API |
| **RPM** | Requests Per Minute — Запросов в минуту | Метрика rate limit API Anthropic |
| **SDK** | Software Development Kit — Набор инструментов разработчика | OpenHands SDK, OpenAI Agents SDK |
| **SFT** | Supervised Fine-Tuning — Дообучение под наблюдением | Этап обучения модели на примерах с правильными ответами |
| **SPA** | Single Page Application — Одностраничное приложение | Архитектура фронтенда (React SPA в OpenHands GUI) |
| **SQL** | Structured Query Language — Язык структурированных запросов | Язык работы с реляционными базами данных |
| **SSH** | Secure Shell — Защищённая оболочка | Протокол удалённого доступа к серверу |
| **SWE** | Software Engineering — Программная инженерия | SWE-Bench — бенчмарк по задачам разработки ПО |
| **SWE-Bench** | Software Engineering Benchmark | Тест: агент решает реальные GitHub Issues в кодовых базах |
| **TCO** | Total Cost of Ownership — Совокупная стоимость владения | Экономический анализ всех затрат на инструмент |
| **TDD** | Test-Driven Development — Разработка через тесты | Сначала пишутся тесты, потом код |
| **UI** | User Interface — Пользовательский интерфейс | Визуальная часть приложения |
| **URL** | Uniform Resource Locator — Унифицированный указатель ресурса | Адрес в интернете |
| **VNC** | Virtual Network Computing — Виртуальные сетевые вычисления | Протокол удалённого рабочего стола (GUI-автоматизация в OpenHands) |
| **VSCode** | Visual Studio Code | Редактор кода от Microsoft (встроен в OpenHands) |
| **WebSocket** | Web Socket — Веб-сокет | Протокол двустороннего соединения в реальном времени |
| **XML** | eXtensible Markup Language — Расширяемый язык разметки | Формат структурированных данных |

---

## 1. Исполнительное резюме

Разница между общением с языковой моделью через браузерный чат (claude.ai, ChatGPT, Gemini Advanced и т.д.) и использованием агентной платформы наподобие **OpenHands** — это качественный, а не количественный разрыв. Чат — это **консультант**, отвечающий текстом. Агент — это **исполнитель**, действующий в реальной среде.

**Ключевые выводы:**

- OpenHands с Claude Sonnet 4.5 (extended thinking) достигает **72% resolve rate** на SWE-Bench Verified — задачах, требующих реальных исправлений в production-кодовых базах. Чат-модели без агентного обвязки показывают менее 5% на тех же задачах (результат начала 2024 года для Claude 2 в ассистированном режиме).
- Агент может автономно работать **более 30 часов** на сложных многоэтапных задачах.
- Разница в архитектуре агента при одинаковой базовой модели даёт до **6 процентных пунктов** разницы в SWE-Bench Pro (Auggie vs Claude Code на Opus 4.5).
- OpenHands является **model-agnostic**: поддерживает Claude, GPT, Gemini, Qwen, DeepSeek и любые OpenAI-совместимые API.

---

## 2. Архитектура OpenHands

OpenHands (ранее OpenDevin) — открытая платформа для создания автономных агентов-разработчиков, построенная на принципе **"агент взаимодействует с миром так же, как человек-разработчик"**.

### 2.1 Основные компоненты

```
┌─────────────────────────────────────────────────────────────┐
│                     OpenHands Ecosystem                      │
├─────────────┬──────────────┬──────────────┬─────────────────┤
│   SDK       │     CLI      │  Local GUI   │  Cloud/Hosted   │
│ (Python)    │  (Terminal)  │  (React SPA) │   (openhands.ai)│
└──────┬──────┴──────┬───────┴──────┬───────┴────────┬────────┘
       │             │              │                │
       └─────────────┴──────────────┴────────────────┘
                              │
                    ┌─────────┴──────────┐
                    │   Agent Runtime     │
                    │  ┌───────────────┐ │
                    │  │  Event Stream  │ │
                    │  │  (State Mgmt) │ │
                    │  └───────────────┘ │
                    │  ┌───────────────┐ │
                    │  │  Sandbox Env  │ │
                    │  │ (Docker/Linux)│ │
                    │  └───────────────┘ │
                    │  ┌───────────────┐ │
                    │  │  Tool System  │ │
                    │  │  (MCP + typed)│ │
                    │  └───────────────┘ │
                    └────────────────────┘
```

### 2.2 Ключевые действия агента (Action Space)

| Действие | Тип | Описание |
|---|---|---|
| `IPythonRunCellAction` | Code | Выполнение Python-кода в Jupyter kernel |
| `CmdRunAction` | Shell | Выполнение bash-команд в sandbox |
| `BrowserInteractiveAction` | Web | Взаимодействие с браузером (BrowserGym DSL) |
| `FileReadAction` | FS | Чтение файлов из рабочего пространства |
| `FileWriteAction` | FS | Запись и изменение файлов |
| `AgentDelegateAction` | Multi-agent | Делегирование суб-агенту |
| `AgentFinishAction` | Control | Завершение задачи |

### 2.3 Модель состояния

OpenHands V1 использует **event-sourced state model** с детерминированным воспроизведением. Состояние — это хронологический поток событий (действия агента + наблюдения), что обеспечивает:
- Полную воспроизводимость сессий
- Отказоустойчивость при длительных задачах
- Аудит каждого шага

---

## 3. Масштабная сравнительная таблица

### Полное сравнение: OpenHands vs. Браузерный чат LLM

| Характеристика | Браузерный чат (claude.ai, ChatGPT и т.д.) | OpenHands (Агент) | Разница |
|---|---|---|---|
| **— ВЫПОЛНЕНИЕ КОДА —** | | | |
| Запуск кода в реальном окружении | ❌ (только симуляция/генерация) | ✅ Docker sandbox | Принципиальная |
| Выполнение bash-команд | ❌ | ✅ | — |
| Запуск тестов | ❌ (только помощь в написании) | ✅ pytest, jest, go test | — |
| Установка зависимостей (pip/npm) | ❌ | ✅ | — |
| Компиляция кода | ❌ | ✅ | — |
| Запуск Docker-контейнеров | ❌ | ✅ | — |
| **— РАБОТА С ФАЙЛОВОЙ СИСТЕМОЙ —** | | | |
| Чтение файлов проекта | ⚠️ Только загруженные вручную | ✅ Полный доступ к репозиторию | Принципиальная |
| Запись и изменение файлов | ❌ | ✅ | — |
| Обход дерева директорий | ❌ | ✅ | — |
| Git-операции (commit, push, PR) | ❌ | ✅ | — |
| Контекст всего репозитория | ❌ | ✅ | — |
| **— БРАУЗЕР И ИНТЕРНЕТ —** | | | |
| Веб-серфинг и поиск | ⚠️ Только с встроенным поиском | ✅ Полноценный Chromium | Значительная |
| Scraping сайтов | ❌ | ✅ | — |
| Взаимодействие с web-UI | ❌ | ✅ BrowserGym | — |
| Открытие локального dev-сервера | ❌ | ✅ (localhost preview) | — |
| **— АВТОНОМНОСТЬ И ДЛИТЕЛЬНОСТЬ —** | | | |
| Максимальная длина задачи | 1 разговор (~hours) | 30+ часов автономной работы | Кардинальная |
| Самокорректировка по ошибкам | ❌ (требует ручного вмешательства) | ✅ Автоматический retry и backtrack | — |
| Многоэтапное планирование | ⚠️ Только текстовое | ✅ С реальным исполнением | — |
| Параллельные задачи | ❌ | ✅ Мульти-агентная координация | — |
| Асинхронная работа (пока пользователь офлайн) | ❌ | ✅ | — |
| **— ИНТЕГРАЦИИ —** | | | |
| GitHub Issues → PR автоматически | ❌ | ✅ | — |
| GitLab MR | ❌ | ✅ | — |
| Jira / Linear интеграция | ❌ | ✅ (в разработке) | — |
| CI/CD взаимодействие | ❌ | ✅ | — |
| IDE (VSCode в браузере) | ❌ | ✅ (встроенный VSCode) | — |
| VNC-десктоп | ❌ | ✅ | — |
| MCP (Model Context Protocol) | ⚠️ Некоторые чаты | ✅ Нативная поддержка | Значительная |
| **— МОДЕЛИ —** | | | |
| Выбор базовой модели | ⚠️ Фиксированная (только платформы) | ✅ Любая LLM через API | Принципиальная |
| Локальные модели (Ollama, llama.cpp) | ❌ | ✅ | — |
| Смешивание моделей (routing) | ❌ | ✅ | — |
| Extended thinking / o1-style reasoning | ⚠️ Только в специальных чатах | ✅ | — |
| **— РАЗРАБОТКА И КАСТОМИЗАЦИЯ —** | | | |
| Создание кастомных агентов | ❌ | ✅ Python API | — |
| Подключение внешних инструментов | ❌ | ✅ MCP + typed tool system | — |
| Оценка через бенчмарки | ❌ | ✅ 15+ встроенных бенчмарков | — |
| Self-hosting / on-premise | ❌ | ✅ Docker deployment | — |
| Enterprise контроль политик | ❌ | ✅ | — |
| **— БЕЗОПАСНОСТЬ И ПРИВАТНОСТЬ —** | | | |
| Изолированное выполнение кода | ❌ | ✅ Docker sandbox | Принципиальная |
| Корпоративная приватность (данные не уходят) | ❌ | ✅ (self-hosted) | — |
| Audit log всех действий | ❌ | ✅ Event stream | — |
| Соответствие GDPR/HIPAA | ❌ | ✅ (self-hosted) | — |
| **— КАЧЕСТВО РЕЗУЛЬТАТОВ —** | | | |
| SWE-Bench Verified (resolve rate) | ~5–10% (без агента) | **53–72%** (с агентом) | 7–14x лучше |
| Реальные GitHub Issues (автоматически) | ❌ | ✅ | — |
| Написание + запуск + починка тестов | ❌ | ✅ | — |
| Многофайловый рефакторинг | ⚠️ Только советы | ✅ Реальные изменения | — |
| **— ПОЛЬЗОВАТЕЛЬСКИЙ ОПЫТ —** | | | |
| Порог входа | ✅ Минимальный | ⚠️ Требует настройки | Чат проще |
| Стоимость на запрос | ✅ Фиксированная подписка | ⚠️ Pay-per-token (дороже) | Чат дешевле |
| Прозрачность действий | ❌ Только текст | ✅ Визуализация каждого шага | Агент лучше |
| Real-time feedback пользователя | ✅ | ✅ | Равно |
| Мобильный доступ | ✅ | ⚠️ Только Cloud версия | Чат лучше |

---

## 4. Сравнение агентных платформ

### 4.1 Основные AI-агенты для разработки (2025–2026)

| Платформа | Тип | Open Source | SWE-Bench Verified | SWE-Bench Pro | Базовые модели | Цена | Особенности |
|---|---|---|---|---|---|---|---|
| **OpenHands** | Автономный агент | ✅ MIT | 53–72% | ~41–46% | Любая (model-agnostic) | $0 (self-hosted) / Pay-per-use | CodeAct архитектура, 64k+ GitHub stars |
| **Devin (Cognition AI)** | Автономный агент | ❌ | ~70%+ | ~23%+ | Проприетарная | $500/мес | Первый "AI software engineer" |
| **Claude Code** | CLI-агент | ❌ | ~70%+ | ~45.89% (Opus 4.5) | Claude Opus/Sonnet | Pay-per-token | Нативная интеграция с Anthropic |
| **Cursor** | IDE-агент | ❌ (частично) | ~60%+ | Сопоставимо с Claude Code | GPT-4o, Claude, Gemini | $20–40/мес | Tab-autocomplete + chat + agent |
| **Auggie (Augment Code)** | CLI-агент | ❌ | — | **51.80%** (лидер SWE-Pro) | Claude Opus 4.5 | Enterprise | Продвинутый контекстный ретривал |
| **GitHub Copilot (Workspace)** | IDE + агент | ❌ | ~50%+ | — | GPT-4o, Claude | $10–19/мес | Тесная интеграция с GitHub |
| **Windsurf (Codeium)** | IDE-агент | ❌ | ~55%+ | — | Claude, GPT | $15/мес | Cascade agent mode |
| **Aider** | CLI-агент | ✅ Apache | ~50%+ | — | Любая | $0 | Легковесный, git-native |
| **SWE-Agent** | Research агент | ✅ MIT | ~43%+ | ~23% (Opus 4.5) | Любая | $0 | Академический, Stanford |
| **Live-SWE-Agent** | Self-evolving агент | ✅ | 79.2% (с Opus 4.5!) | 45.8% (Sonnet 4.5) | Claude, Gemini | $0 | Самосовершенствование во время работы |
| **Devlo** | Cloud-агент | ❌ | 70.2% | — | Claude 3.7+o3+Gemini 2.5 | Enterprise | Multi-model ансамблевый подход |

### 4.2 Сравнение SDK агентных фреймворков

| Функция | OpenHands SDK | OpenAI Agents SDK | Claude Agent SDK (Anthropic) | Google ADK |
|---|---|---|---|---|
| Event-sourced state | ✅ Детерминированный replay | ❌ | ❌ | ❌ |
| Встроенный REST/WebSocket сервер | ✅ | ❌ (нужен Temporal) | ❌ | ❌ |
| Browser-based VSCode IDE | ✅ | ❌ | ❌ | ❌ |
| VNC desktop | ✅ | ❌ | ❌ | ❌ |
| Persistent Chromium | ✅ | ❌ | ❌ | ❌ |
| MCP интеграция | ✅ Нативная | ✅ | ✅ | ✅ |
| Typed tool system | ✅ | ✅ | ✅ | ✅ |
| Sandbox (Docker) | ✅ | ❌ | ❌ | ⚠️ |
| Multi-agent coordination | ✅ | ✅ | ⚠️ | ✅ |
| Production deployment | ✅ Нативно | ⚠️ Temporal required | ⚠️ | ✅ |
| Open source | ✅ MIT | ❌ | ❌ | ✅ Apache |
| Model-agnostic | ✅ | ✅ | ❌ (только Claude) | ✅ |
| Self-hosting | ✅ | ❌ | ❌ | ✅ |
| SWE-Bench score | 72% (Sonnet 4.5) | Не заявлено | Не заявлено | Не заявлено |

---

## 5. Топ-моделей для кодинга

### 5.1 Рейтинг моделей по SWE-Bench Verified (2025–2026)

| Место | Модель | SWE-Bench Verified | SWE-Bench Pro | Тип | Open Source | Особенности для кода |
|---|---|---|---|---|---|---|
| 1 | **Claude Opus 4.6 (Thinking)** + Live-SWE-agent | **79.2%** | — | Проприетарная | ❌ | Extended thinking, 200K контекст |
| 2 | **Gemini 3 Pro** + Live-SWE-agent | 77.4% | — | Проприетарная | ❌ | 2M токен контекст |
| 3 | **GPT-5.2** | 75.4% | ~14.9% (private) | Проприетарная | ❌ | Token-efficient |
| 4 | **TRAE** (Claude 4 Sonnet + Opus 3.7) | 75.2% | — | Multi-model | ❌ | Ансамблевый подход |
| 5 | **Claude Sonnet 4.5** (extended thinking) | 72% (OpenHands SDK) | 45.8% | Проприетарная | ❌ | Оптимум цена/качество |
| 6 | **Devlo** (Claude 3.7 + o3 + Gemini 2.5) | 70.2% | — | Multi-model | ❌ | LLM-as-a-judge |
| 7 | **Claude Opus 4.5** | ~70%+ | 45.89% | Проприетарная | ❌ | Лучший соло-результат |
| 8 | **Auggie** (Opus 4.5) | — | **51.80%** | Проприетарная | ❌ | Лидер SWE-Pro |
| 9 | **GLM-4.7** | ~65%+ | — | Проприетарная | ✅ | Лучшая open-source |
| 10 | **Qwen3 Coder 480B** | ~60%+ | 41.21% (OpenHands) | Открытые веса | ✅ | Конкурентная open-weight |
| 11 | **DeepSeek-V3.2** | ~55%+ | — | Открытые веса | ✅ | 68x дешевле Opus |
| 12 | **Claude 3.7 Sonnet** | 62.3% | — | Проприетарная | ❌ | 128K output tokens |
| 13 | **Kimi K2 Thinking** | Топ open-source | — | Открытые веса | ✅ | Лучший pass@1 в open |
| 14 | **Qwen3-Coder-Next** | ~50%+ | — | Открытые веса | ✅ | ~3B активных параметров |
| 15 | **Devstral-2-123B** | ~45%+ | — | Открытые веса | ✅ | Специализированный для кода |

---

## 6. Технологии внутри LLM-моделей

### 6.1 Ключевые технологии, влияющие на качество кодинга

| Технология | Что это | Влияние на кодинг | Примеры моделей |
|---|---|---|---|
| **RLHF / RLAIF** | Обучение с подкреплением от человеческой / AI-обратной связи | Корректность кода, следование инструкциям, безопасность | Claude, GPT-4/5, Gemini |
| **Constitutional AI** | Самооценка модели по набору принципов | Отказ от небезопасного кода, надёжность | Claude |
| **Extended Thinking / Chain-of-Thought** | Явный "внутренний монолог" перед ответом | +10–20% SWE-Bench, сложные алгоритмы | Claude Opus 4+ (thinking), o1/o3, Gemini 2.5 |
| **Long Context Window** | 128K–2M токенов | Чтение целых кодовых баз, документации | Gemini (2M), Claude (200K), GPT-5 (128K+) |
| **Function Calling / Tool Use** | Структурированный вызов внешних инструментов | Основа агентных возможностей | Все топ-модели |
| **Speculative Decoding** | Параллельная генерация через черновик-модель | Ускорение в 2–4x, важно для длинных кодовых задач | Gemini Flash, Haiku |
| **MoE (Mixture of Experts)** | Активация только части параметров | Высокая эффективность при большом числе параметров | Qwen3 (235B, 22B active), Mixtral |
| **Byte-Pair Encoding (BPE)** | Токенизация кода | Точное представление синтаксиса, отступов | Все модели |
| **Prefix Caching / KV Cache** | Кэширование вычислений для повторяющегося контекста | Снижение стоимости в 5–10x для агентных задач | Claude, GPT-4, Gemini |
| **Flash Attention** | Оптимизированный механизм внимания | Позволяет работать с длинным контекстом | Все топ-модели |
| **Code-specific pretraining** | Дообучение на GitHub, StackOverflow и т.д. | Знание паттернов, библиотек, ошибок | DeepSeek-Coder, Qwen-Coder, Devstral |
| **Instruction Following Fine-tuning (IFT)** | SFT на парах инструкция→ответ | Точность следования требованиям задачи | Все SOTA модели |
| **Retrieval-Augmented Generation (RAG)** | Извлечение релевантного кода из индекса | Работа с крупными кодовыми базами | Cursor (codebase indexing), Copilot |
| **Multi-token prediction** | Предсказание нескольких токенов одновременно | Ускорение + лучшая когерентность кода | Экспериментально (Meta, DeepSeek) |
| **Inference-time scaling (o1 style)** | Больше токенов на рассуждение = лучший результат | GPT-4o: +25% при high-effort, o3: +40% | OpenAI o1/o3/o4, Claude Thinking |

### 6.2 Технологии по семействам моделей

| Семейство | Архитектура | Контекст | Специализация по коду | Ключевые технологии |
|---|---|---|---|---|
| **Claude 4.x** | Transformer dense/sparse | 200K | Высокая | Constitutional AI, Extended Thinking, Prefix Caching |
| **GPT-5.x / o-series** | Transformer + RL reasoning | 128K+ | Очень высокая | RLHF, Inference-time scaling, Code Interpreter |
| **Gemini 3.x** | Mixture + MultiModal | 2M | Высокая | Speculative Decoding, native multimodal, Flash variants |
| **Qwen3 Coder** | MoE (235B / 22B active) | 128K | Специализированная | MoE efficiency, code-specific SFT, open weights |
| **DeepSeek-V3.x** | MoE | 128K | Специализированная | Extremely cost-efficient, distillation techniques |
| **Kimi K2** | Dense / MoE | 128K+ | Высокая | Tool-use optimized, strong function calling |
| **GLM-4.7** | Transformer | 128K | Высокая | Open-source лидер, tool calling, code execution |
| **Devstral** | На базе Mistral | 64K+ | Специализированная | Code-only SFT, agent-optimized |
| **Llama 4** | MoE Scout (17B/16E) | 512K+ | Средняя | Open weights, Apache 2.0 |

---

## 7. Технологии внутри агентных систем

### 7.1 Технологический стек агентных платформ

| Технология | Роль в агенте | OpenHands | Claude Code | Cursor | Описание |
|---|---|---|---|---|---|
| **CodeAct** | Основной агентный цикл | ✅ CodeAct 2.1 | ❌ | ❌ | Действия = исполняемый код (Python/Bash) вместо JSON-инструментов |
| **ReAct (Reason+Act)** | Цикл планирования | ✅ | ✅ | ✅ | Попеременное рассуждение и действие |
| **Docker Sandbox** | Изолированное выполнение | ✅ | ⚠️ | ❌ | Полная изоляция кода от хоста |
| **Event Stream (event-sourcing)** | Управление состоянием | ✅ V1 | ❌ | ❌ | Хронологический лог всех событий |
| **BrowserGym** | Автоматизация браузера | ✅ | ❌ | ❌ | DSL для веб-взаимодействий |
| **MCP (Model Context Protocol)** | Внешние инструменты | ✅ | ✅ | ✅ | Стандарт Anthropic для tool-calling |
| **Multi-Agent Delegation** | Параллелизм задач | ✅ | ❌ | ❌ | Суб-агенты для специализированных задач |
| **Retrieval / Code Indexing** | Поиск по кодовой базе | ⚠️ Базовый | ⚠️ | ✅ Продвинутый | Эмбеддинги, AST-анализ |
| **Persistent Chromium** | Веб-состояние между сессиями | ✅ | ❌ | ❌ | Cookies, сессии сохраняются |
| **VSCode в браузере** | IDE в агенте | ✅ code-server | ❌ | ✅ Нативный | Редактирование с подсветкой |
| **VNC Desktop** | GUI-автоматизация | ✅ | ❌ | ❌ | Управление десктоп-приложениями |
| **WebSocket real-time** | Стриминг действий | ✅ | ✅ | ✅ | Живая трансляция прогресса |
| **Deterministic Replay** | Воспроизводимость | ✅ | ❌ | ❌ | Повтор любой сессии побайтно |
| **LLM-as-a-judge** | Оценка патчей | ⚠️ | ❌ | ❌ | Используется в Devlo, TRAE |
| **Inference-time self-improvement** | Самоэволюция | ⚠️ | ❌ | ❌ | Live-SWE-Agent (исследование) |
| **GitHub Actions / CI integration** | DevOps автоматизация | ✅ | ✅ | ❌ | Тесты в CI/CD по PR |

---

## 8. Связь технологий моделей и агентов

Технологии LLM и агентных систем образуют взаимоусиливающую экосистему. Ниже показаны ключевые связи:

```
ТЕХНОЛОГИИ МОДЕЛИ               ТЕХНОЛОГИИ АГЕНТА
─────────────────                ─────────────────
Extended Thinking     ──────►   Многошаговое планирование
  (Claude, o1/o3)               (ReAct, CodeAct)
                                        │
Long Context (200K+)  ──────►   Контекст всего репозитория
                                Без chunking-ограничений
                                        │
Function Calling /    ──────►   MCP Tools / BrowserGym /
Tool Use              ◄──────   Typed Tool System
(двунаправленная связь)                 │
                                        │
Prefix Caching        ──────►   Экономия токенов в длинных
                                агентных сессиях (5–10x)
                                        │
Code-specific SFT     ──────►   Точность в CodeAct
(DeepSeek, Qwen-Coder)          (Python/Bash как action space)
                                        │
Speculative Decoding  ──────►   Быстрая итерация в
(Gemini Flash)                  Retry-циклах агента
                                        │
MoE Architecture      ──────►   Стоимость агентных
(Qwen, DeepSeek)                сессий снижается
                                        │
RLHF / Constitutional ──────►   Надёжность sandbox:
AI                               агент не ломает систему
                                        │
Inference-time        ──────►   Live-SWE-Agent: самоген.
scaling               ◄──────   инструментов во время работы
```

### 8.1 Синергетические пары технологий

| Технология модели | Технология агента | Совместный эффект |
|---|---|---|
| Extended Thinking (Claude/o-series) | CodeAct Action Space | Глубокое планирование → точные многофайловые правки |
| Long Context (Gemini 2M) | Event Stream (весь лог) | Агент "помнит" всю историю сессии без truncation |
| Function Calling | MCP Protocol | Стандартизированный интерфейс: одна модель — любой инструмент |
| Prefix Caching | Repeated System Prompts в агенте | До 10x снижение стоимости длинных сессий |
| Code SFT (Qwen-Coder) | Docker Sandbox (реальный запуск) | Модель знает синтаксис → агент проверяет реальным запуском |
| RLHF Instruction Following | Multi-Agent Delegation | Надёжная передача суб-задач специализированным агентам |
| Speculative Decoding | Retry Loops в агенте | Быстрый перезапуск при ошибке без задержек |
| MoE (selective experts) | Tool Routing в агенте | Похожая идея: активируем нужную "экспертизу" для задачи |
| LLM-as-a-judge (multi-model) | Patch Selection в агенте | Ансамбль Devlo: 70.2% за счёт диверсити + отбора |

---

## 9. Качество кодинга

### 9.1 Сравнение по типам задач

| Задача | Чат LLM | OpenHands Агент | Преимущество агента |
|---|---|---|---|
| Написание функции с нуля | ★★★★☆ | ★★★★★ | Агент проверяет и тестирует |
| Многофайловый рефакторинг | ★★☆☆☆ | ★★★★☆ | Агент видит все файлы, меняет их |
| Реализация фичи по GitHub Issue | ★★☆☆☆ | ★★★★☆ | Агент читает issue, коммитит PR |
| TDD (тесты → код) | ★★★☆☆ | ★★★★★ | Агент запускает тесты реально |
| Интеграционное тестирование | ★☆☆☆☆ | ★★★★☆ | Агент поднимает сервисы, запускает |
| Миграция баз данных | ★★☆☆☆ | ★★★★☆ | Агент выполняет SQL, проверяет |
| Оптимизация производительности | ★★★☆☆ | ★★★★★ | Агент профилирует, измеряет реально |
| Написание документации | ★★★★★ | ★★★★★ | Равно (текстовая задача) |
| Dependency upgrades | ★★☆☆☆ | ★★★★☆ | Агент устанавливает, запускает тесты |
| Security audit | ★★★☆☆ | ★★★★☆ | Агент запускает сканеры (bandit, semgrep) |

### 9.2 Ключевые метрики качества

**SWE-Bench Verified (2025):** Тест на 500 реальных GitHub Issues

| Сценарий | Resolve Rate |
|---|---|
| Лучший одиночный агент (Live-SWE-Agent + Opus 4.6) | **79.2%** |
| OpenHands SDK + Claude Sonnet 4.5 (extended thinking) | **72.0%** |
| OpenHands CodeAct 2.1 + Claude Sonnet 3.5 | **53.0%** |
| Без агента (чистая модель, assisted, Claude 2, 2024) | ~4.8% |
| Первый Devin (2024) | 13.86% |

**SWE-Bench Pro (реалистичный, multi-language, 2025):**

| Агент + Модель | SWE-Pro Score |
|---|---|
| Auggie + Claude Opus 4.5 | 51.80% |
| Claude Code + Claude Opus 4.5 | ~45.89% |
| Live-SWE-Agent + Sonnet 4.5 | 45.8% |
| OpenHands + Qwen3 Coder 480B | 41.21% |
| SWE-Agent + Opus 4.5 (baseline) | ~23% |

---

## 10. Траблшутинг и отладка

### 10.1 Сравнение подходов к отладке

| Этап отладки | Чат | OpenHands |
|---|---|---|
| **Воспроизведение ошибки** | Нельзя — только анализ стека | ✅ Запускает код, видит реальную ошибку |
| **Интерпретация stack trace** | ★★★★★ | ★★★★★ |
| **Поиск первопричины** | ★★★☆☆ (по тексту) | ★★★★★ (по реальному исполнению) |
| **Добавление print/logging** | ★★★★☆ (советует) | ★★★★★ (делает и запускает) |
| **Шаги отладки с pdb/debugpy** | ★★★☆☆ (советует) | ★★★★☆ (выполняет интерактивно) |
| **Проверка гипотезы** | ★★★☆☆ (теоретически) | ★★★★★ (реальный эксперимент) |
| **Regression testing** | ★★☆☆☆ (пишет тест) | ★★★★★ (пишет + запускает) |
| **Environment issues** | ★★☆☆☆ (советует) | ★★★★☆ (pip install, env-check) |
| **Race conditions / async bugs** | ★★☆☆☆ | ★★★★☆ (может запустить стресс-тест) |
| **Memory leaks** | ★★☆☆☆ | ★★★★☆ (tracemalloc, valgrind) |

### 10.2 Жизненный цикл отладки в OpenHands

```
[Issue описание]
       │
       ▼
[Агент читает codebase]
       │
       ▼
[Воспроизводит ошибку в sandbox]
       │
       ▼
[Анализирует вывод]
       │
       ▼
[Формулирует гипотезу] ◄──────────────────┐
       │                                   │
       ▼                                   │
[Вносит правку]                     [Нет — retry]
       │
       ▼
[Запускает тесты] ────► [Тесты прошли?] ──► [Да → Commit + PR]
                                │
                         [Нет → analyse]
```

---

## 11. Code Review

### 11.1 Возможности Code Review

| Аспект Code Review | Чат | OpenHands |
|---|---|---|
| Анализ изменений (diff) | ★★★★☆ | ★★★★★ (видит полный контекст PR) |
| Поиск багов | ★★★★☆ | ★★★★★ (+запускает тесты) |
| Security vulnerabilities | ★★★★☆ | ★★★★★ (+bandit/semgrep автоматически) |
| Code style / linting | ★★★☆☆ | ★★★★★ (flake8, eslint реально запускает) |
| Performance review | ★★★☆☆ | ★★★★☆ (профилирует если нужно) |
| Проверка тест-покрытия | ★★★☆☆ | ★★★★★ (coverage.py, nyc) |
| Архитектурные замечания | ★★★★★ | ★★★★☆ |
| Автоисправление замечаний | ❌ | ✅ |
| Обратная связь в PR-комментариях | ❌ | ✅ (через GitHub API) |
| Batch review нескольких файлов | ★★☆☆☆ | ★★★★★ |

---

## 12. Аналитика и исследовательские задачи

| Задача | Чат | OpenHands |
|---|---|---|
| Анализ данных (pandas, numpy) | ★★★★☆ (только код) | ★★★★★ (код + запуск + вывод) |
| Визуализация (matplotlib, plotly) | ★★★☆☆ (описывает) | ★★★★★ (рендерит, сохраняет) |
| Работа с БД (SQL-запросы) | ★★★★☆ | ★★★★★ (выполняет запросы) |
| Парсинг веб-сайтов | ★★★★☆ (код) | ★★★★★ (BeautifulSoup + Selenium) |
| API-интеграция | ★★★★☆ | ★★★★★ (реальные HTTP-запросы) |
| Jupyter Notebook workflow | ★★★☆☆ | ★★★★★ (IPython kernel встроен) |
| ML-эксперименты | ★★★☆☆ | ★★★★☆ (GPU доступ ограничен) |
| Обработка логов | ★★★★☆ | ★★★★★ (grep/awk + python) |
| Мониторинг метрик системы | ★★☆☆☆ | ★★★★☆ (ps, top, iostat) |
| Генерация отчётов | ★★★★☆ | ★★★★★ (PDF/HTML + данные) |

---

## 13. Бенчмарки и реальные метрики

### 13.1 Поддерживаемые бенчмарки в OpenHands

OpenHands включает **15+ встроенных бенчмарков** для оценки агентов:

| Бенчмарк | Тип задачи | Лучший результат (2025) |
|---|---|---|
| **SWE-Bench Verified** | GitHub Issues (Python) | 79.2% (Live-SWE-Agent + Opus 4.6) |
| **SWE-Bench Pro** | Multi-lang, enterprise | 51.80% (Auggie + Opus 4.5) |
| **GAIA** | Общие компьютерные задачи | 67.9% (OpenHands SDK + Sonnet 4.5) |
| **WebArena** | Веб-навигация | ~40%+ |
| **HumanEval** | Алгоритмические задачи | 90%+ (лучшие модели) |
| **MBPP** | Python programming | 85%+ |
| **LiveCodeBench** | Новые Leetcode-задачи | 60–75% |
| **Commit0** | Написание кода с нуля | ~30–40% |

### 13.2 Динамика прогресса (SWE-Bench Verified)

| Год | Лучший результат | Система |
|---|---|---|
| 2024 Q1 | 13.86% | Devin (первое поколение) |
| 2024 Q2 | ~20% | Различные агенты |
| 2024 Q4 | ~40% | OpenHands + Claude 3.5 |
| 2025 Q1 | 53% | OpenHands CodeAct 2.1 |
| 2025 Q2 | ~70% | Несколько систем |
| 2025 Q4 | **79.2%** | Live-SWE-Agent + Opus 4.6 |

---

## 14. Экономика и TCO

### 14.1 Сравнение стоимости

| Сценарий | Инструмент | Примерная стоимость | Примечания |
|---|---|---|---|
| **Индивидуальный разработчик, лёгкие задачи** | Чат (Claude Pro) | $20/мес | Неограниченное общение |
| **Индивидуальный разработчик, агент** | OpenHands + DeepSeek V3 | $5–30/мес | Pay-per-token, дешёвая модель |
| **Индивидуальный разработчик, агент топ** | OpenHands + Opus 4.5 | $50–200/мес | 30+ часовые задачи — дорого |
| **Команда 10 чел., IDE агент** | Cursor Team | $400/мес | $40/user |
| **Команда 10 чел., автономный агент** | OpenHands Cloud | $200–1000/мес | Зависит от задач |
| **Enterprise, self-hosted** | OpenHands + локальные модели | $0 API + инфра | Полная приватность |
| **Enterprise, Devin** | Cognition Devin | $5000+/мес | Enterprise pricing |

### 14.2 ROI-факторы

Агент окупается при:
- Задачах длиннее **2–3 часов** одного разработчика
- Регулярных **рутинных задачах** (dependency updates, lint fixes, тесты)
- **GitHub Issues** с хорошим описанием (автоматическое закрытие)
- **Техническом долге**: рефакторинг + тесты одновременно
- **Ночных задачах**: агент работает пока команда спит

---

## 15. Рекомендации и сценарии применения

### 15.1 Когда использовать чат

- **Быстрые вопросы** о синтаксисе, алгоритмах, архитектурных решениях
- **Обучение**: объяснение концепций, примеры кода
- **Мозговой штурм**: обсуждение архитектуры
- **Небольшие правки** (1–5 строк) с немедленной проверкой вручную
- **Написание документации** и README
- **Mobile-доступ** или когда нет времени настраивать окружение

### 15.2 Когда использовать OpenHands

- **GitHub Issues**: автоматическое создание PR
- **Многофайловые задачи**: рефакторинг, миграции
- **TDD**: написать тесты → заставить их пройти
- **Dependency updates**: обновить + исправить breaking changes
- **Автоматизированный code review** с реальным запуском линтеров
- **Исследование незнакомых кодовых баз**: агент сам читает и исследует
- **DevOps и CI/CD** задачи
- **Длительные исследовательские задачи** (скрейпинг, анализ данных)

### 15.3 Оптимальный рабочий процесс (гибридный)

```
Чат (планирование/архитектура)
         │
         ▼
OpenHands (backend 80% работы)
         │
         ├─► IDE (Cursor/Windsurf) для доработки UI
         │
         ├─► Code Review агент (OpenHands) для проверки
         │
         └─► CI/CD автоматические тесты
```

> Пользователи сообщают о сохранении **значительного времени** при использовании OpenHands для backend-задач в связке с интерактивным IDE для UI и финальных правок.

---

## Заключение

OpenHands представляет качественный скачок от консультативного чата к автономному исполнению задач. Ключевая точка сравнения:

| Парадигма | Чат LLM | OpenHands Агент |
|---|---|---|
| **Роль** | Консультант | Исполнитель |
| **Среда** | Текст | Реальная Linux-система |
| **Верификация** | Человек проверяет | Тесты и CI проверяют |
| **Масштаб задачи** | Часы разговора | Дни автономной работы |
| **SWE-Bench** | ~5% | **79%** (лучший агент) |

Разрыв будет только расти с улучшением как базовых моделей (extended thinking, более длинный контекст), так и агентных технологий (self-evolving agents, лучший retrieval, multi-agent координация).

---

*Источники: OpenHands arxiv paper (2407.16741v3), OpenHands SDK paper (2511.03690), SWE-Bench официальная таблица лидеров, SWE-rebench.com, Scale AI SWE-Bench Pro, Live-SWE-Agent leaderboard, AMD developer article (2025), Augment Code blog, All Hands AI blog.*
